{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe6bc396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/s5982960/OCR-icelandic/.venv/lib/python3.13/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/scratch/s5982960/OCR-icelandic/.venv/lib/python3.13/site-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11269248, 2257542128)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "from transformers import (\n",
    "    AutoProcessor,\n",
    "    BitsAndBytesConfig,\n",
    "    Idefics3ForConditionalGeneration,\n",
    ")\n",
    "\n",
    "USE_LORA = True\n",
    "USE_QLORA = False\n",
    "SMOL = True\n",
    "\n",
    "model_id = \"HuggingFaceTB/SmolVLM-Base\" if SMOL else \"HuggingFaceM4/Idefics3-8B-Llama3\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "if USE_QLORA or USE_LORA:\n",
    "    lora_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=8,\n",
    "        lora_dropout=0.1,\n",
    "        target_modules=[\n",
    "            \"down_proj\",\n",
    "            \"o_proj\",\n",
    "            \"k_proj\",\n",
    "            \"q_proj\",\n",
    "            \"gate_proj\",\n",
    "            \"up_proj\",\n",
    "            \"v_proj\",\n",
    "        ],\n",
    "        use_dora=False if USE_QLORA else True,\n",
    "        init_lora_weights=\"gaussian\",\n",
    "    )\n",
    "    lora_config.inference_mode = False\n",
    "    if USE_QLORA:\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "\n",
    "    print(\"Loading model...\")\n",
    "    model = Idefics3ForConditionalGeneration.from_pretrained(\n",
    "        model_id,\n",
    "        quantization_config=bnb_config if USE_QLORA else None,\n",
    "        # _attn_implementation=\"flash_attention_2\",\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    model.add_adapter(lora_config)\n",
    "    model.enable_adapters()\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    print(model.get_nb_trainable_parameters())\n",
    "else:\n",
    "    model = Idefics3ForConditionalGeneration.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        # _attn_implementation=\"flash_attention_2\",\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    # if you'd like to only fine-tune LLM\n",
    "    for param in model.model.vision_model.parameters():\n",
    "        param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3867db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load adapter weights if needed\n",
    "model.load_adapter(\"./SmolVLM-Base-ocr-isl/checkpoint-1500\", adapter_name=\"checkpoint-1500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a104728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/s5982960/OCR-icelandic/.venv/lib/python3.13/site-packages/transformers/utils/hub.py:916: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f7dc6a05bb4f81a09d8ef5a4615726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4119ab79bd66454eb7a295d5cb96fc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452fb96a80d84f05b6cf78b70380294c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...oint-1500/adapter_model.safetensors:   1%|1         |  558kB / 45.2MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cdce1d4dc24da3b7caf4c6f36b4e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...phnv42jdb/adapter_model.safetensors:   3%|2         | 1.15MB / 45.2MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Sigurdur/SmolVLM-Base-ocr-isl-checkpoint-1500/commit/0f07d0561750399354e4a54ac317f1c0c05b29c5', commit_message='Upload model', commit_description='', oid='0f07d0561750399354e4a54ac317f1c0c05b29c5', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Sigurdur/SmolVLM-Base-ocr-isl-checkpoint-1500', endpoint='https://huggingface.co', repo_type='model', repo_id='Sigurdur/SmolVLM-Base-ocr-isl-checkpoint-1500'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# merge adapter weights into model\n",
    "model.merge_adapter([\"checkpoint-1500\"])\n",
    "model.eval()\n",
    "\n",
    "# push to hub\n",
    "model.push_to_hub(\"SmolVLM-Base-ocr-isl-checkpoint-1500\", use_auth_token=True)\n",
    "# processor.push_to_hub(\"SmolVLM-Base-ocr-isl-checkpoint-1500\", use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference example\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/4/4b/Example.jpg\"\n",
    "from PIL import Image\n",
    "import requests\n",
    "image = Image.open(requests.get(image_url, stream=True).raw).convert(\"RGB\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OCR-icelandic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
